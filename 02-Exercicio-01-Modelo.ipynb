{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 3 - Case\n",
    "  \n",
    "#### Conforme planilha de dados fornecida. \n",
    "Deseja-se prospectar empresas que possuam soluções em **tratamento de água** , \n",
    "principalmente,  elativas à : **solutions on waste and water, Improve water quality and\n",
    "water efficiency use, water contamination, water for human consumption, water resources** ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declarações Importações de Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import scipy.sparse\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from gensim import matutils\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "from sklearn.feature_extraction.text import (TfidfVectorizer,\n",
    "                                             CountVectorizer)\n",
    "from sklearn.model_selection import (train_test_split,\n",
    "                                     GridSearchCV)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import (make_pipeline,\n",
    "                              Pipeline)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declarações de Constantes Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path().absolute()\n",
    "SOURCE_SUBDIR = 'Data'\n",
    "DEST_SUBDIR = 'Data'\n",
    "DATA_FILE_NAME = 'data.parquet'\n",
    "FULL_DATA_FILE_NAME = ROOT_DIR / SOURCE_SUBDIR / DATA_FILE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do Modelo - Exercício 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados do Excel\n",
    "df = pd.read_parquet(FULL_DATA_FILE_NAME)\n",
    "\n",
    "# Carrega os registros selecionados\n",
    "df_selected = pd.read_parquet(ROOT_DIR / SOURCE_SUBDIR /'Selected_Data.parquet')\n",
    "\n",
    "# Carrega os registros rotulados, deve conter os indices originais\n",
    "df_final = pd.read_parquet(ROOT_DIR / SOURCE_SUBDIR /'Labeled_Data.parquet')\n",
    "\n",
    "tfidf_matrix = joblib.load(ROOT_DIR / SOURCE_SUBDIR / 'tfidf_matrix.pkl')\n",
    "# Carrega o vetorizador alinhado com os dados selecionados\n",
    "tfidf_matrix_restrita = joblib.load(ROOT_DIR / SOURCE_SUBDIR / 'tfidf_matrix_restrita.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando características para modelagem\n",
    "X = df_final[['original_water_term_count', 'altered_water_term_count', 'extended_water_term_count', 'topic']]\n",
    "# Convertendo o DataFrame de características em matriz esparsa\n",
    "X_sparse = csr_matrix(X.values)\n",
    "\n",
    "# Concatenando a matriz esparsa de características com a matriz TF-IDF restrita\n",
    "X_combined = hstack([X_sparse, tfidf_matrix_restrita])\n",
    "# Dividindo o conjunto de dados combinado em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, df_final['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dataframe com todos os dados\n",
    "df_final = df.merge(df_selected[['label']], left_index=True, right_index=True, how='inner')\n",
    "# Selecionando características para modelagem\n",
    "X = df_final[['original_water_term_count', 'altered_water_term_count', 'extended_water_term_count', 'topic']]\n",
    "# Convertendo o DataFrame de características em matriz esparsa\n",
    "X_sparse = csr_matrix(X.values)\n",
    "# Restringir tfidf_matrix aos registros rotulados\n",
    "#tfidf_matrix_restrita = tfidf_matrix[df_final.index]\n",
    "\n",
    "# Concatenando a matriz esparsa de características com a matriz TF-IDF restrita\n",
    "X_combined = hstack([X_sparse, tfidf_matrix_restrita])\n",
    "# Dividindo o conjunto de dados combinado em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, df_final['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística (Melhor caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este será o modelo escolhido devido a ter a melhor relação Acurácia e Recall. Está longe de \n",
    "ser um modelo bom, para isto seria necessário um trabalho de reavaliação das features extraídas,\n",
    "do preprocessamento de texto e outros pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'C': 0.1, 'solver': 'saga'}\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Menos relevante       0.00      0.00      0.00         1\n",
      "  Não relevante       1.00      1.00      1.00         5\n",
      "      Relevante       0.67      1.00      0.80         2\n",
      "\n",
      "       accuracy                           0.88         8\n",
      "      macro avg       0.56      0.67      0.60         8\n",
      "   weighted avg       0.79      0.88      0.82         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Definindo o modelo\n",
    "log_reg = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "\n",
    "# Definindo o espaço de hiperparâmetros para exploração\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'saga']\n",
    "}\n",
    "\n",
    "# Configurando o GridSearchCV\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Realizando o GridSearchCV com os dados de treinamento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Verificando os melhores parâmetros encontrados\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Avaliando o desempenho do melhor modelo encontrado no conjunto de teste\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/pabloernesto/Seagate Expansion Drive/Work/Projects/Desafios/FirstDecision/Prospect-Canadian-Water-Companies/Data/tfidf_matrix_restrita.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvando o melhor modelo encontrado pelo GridSearchCV\n",
    "joblib.dump(best_model, ROOT_DIR / SOURCE_SUBDIR / 'best_logistic_regression_model.pkl')\n",
    "\n",
    "# Salvando o vetorizador\n",
    "joblib.dump(tfidf_matrix_restrita, ROOT_DIR / SOURCE_SUBDIR / 'tfidf_matrix_restrita.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A identificação de não relevantes é ótima (na verdade perfeita demais), a de relevantes não tão boa, mas a de menos relevantes está nula... \n",
    "Irei testar outro algoritmo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Menos relevante       0.00      0.00      0.00         1\n",
      "  Não relevante       0.71      1.00      0.83         5\n",
      "      Relevante       1.00      0.50      0.67         2\n",
      "\n",
      "       accuracy                           0.75         8\n",
      "      macro avg       0.57      0.50      0.50         8\n",
      "   weighted avg       0.70      0.75      0.69         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o modelo de Florestas Aleatórias\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Treinar o modelo com o conjunto de treinamento\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Prever os rótulos para o conjunto de teste\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho do modelo\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A identificação de não relevantes é ótima, a de relevantes não tão boa, mas a de menos relevantes está nula (novamente)... \n",
    "Vou tentar fazer um balanceamento de calsses usando SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE (Para balanceamento de classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Relevante          16\n",
      "Não relevante      16\n",
      "Menos relevante    16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Supondo que a classe minoritária tenha 5 amostras, ajuste n_neighbors para 4 ou menos\n",
    "smote = SMOTE(random_state=42, k_neighbors=4)\n",
    "\n",
    "# Aplicando o SMOTE ajustado ao conjunto de treinamento\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificando a nova distribuição das classes\n",
    "print(pd.Series(y_train_smote).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reavaliando Logistic Regression (com SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Logística com Dados Balanceados:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Menos relevante       0.00      0.00      0.00         1\n",
      "  Não relevante       1.00      0.80      0.89         5\n",
      "      Relevante       0.50      1.00      0.67         2\n",
      "\n",
      "       accuracy                           0.75         8\n",
      "      macro avg       0.50      0.60      0.52         8\n",
      "   weighted avg       0.75      0.75      0.72         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inicializando o modelo de Regressão Logística com os melhores parâmetros encontrados anteriormente\n",
    "log_reg_balanced = LogisticRegression(C=0.1, solver='saga', max_iter=1000, multi_class='multinomial')\n",
    "\n",
    "# Treinando o modelo com os dados balanceados\n",
    "log_reg_balanced.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Previsões no conjunto de teste\n",
    "y_pred_log_reg = log_reg_balanced.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho\n",
    "print(\"Regressão Logística com Dados Balanceados:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não houve mudança com os dados balanceados... Podeindicar overfiting dos dados criados pelo SMOTE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redes Neurais (com SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempenho do MLPClassifier após correção:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Menos relevante       0.00      0.00      0.00         1\n",
      "  Não relevante       0.67      0.80      0.73         5\n",
      "      Relevante       0.50      0.50      0.50         2\n",
      "\n",
      "       accuracy                           0.62         8\n",
      "      macro avg       0.39      0.43      0.41         8\n",
      "   weighted avg       0.54      0.62      0.58         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Criando um pipeline com StandardScaler configurado corretamente para matrizes esparsas e MLPClassifier\n",
    "mlp_pipeline = make_pipeline(StandardScaler(with_mean=False), MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', max_iter=1000, random_state=42))\n",
    "\n",
    "# Treinando o pipeline nos dados balanceados pelo SMOTE\n",
    "mlp_pipeline.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred_mlp = mlp_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do MLPClassifier\n",
    "print(\"Desempenho do MLPClassifier após correção:\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM (com SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempenho do SVM:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Menos relevante       0.00      0.00      0.00         1\n",
      "  Não relevante       0.67      0.80      0.73         5\n",
      "      Relevante       0.50      0.50      0.50         2\n",
      "\n",
      "       accuracy                           0.62         8\n",
      "      macro avg       0.39      0.43      0.41         8\n",
      "   weighted avg       0.54      0.62      0.58         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pabloernesto/anaconda3/envs/firstenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Definindo o pipeline com padronização e SVC\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),  # with_mean=False é importante para dados esparsos\n",
    "    ('svc', SVC(kernel='linear', C=1))\n",
    "])\n",
    "\n",
    "# Treinando o pipeline nos dados balanceados pelo SMOTE\n",
    "svm_pipeline.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred_svm = svm_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do SVM\n",
    "print(\"Desempenho do SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado parecido ao de Redes Neurais..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo escolhiodo é a Regressão logistica devido aos seguintes fatores:\n",
    "\n",
    "Maior acurácia geral de 0.88 (88%)\n",
    "\n",
    "O modelo teve uma precisão e recall de 1.00 (100%) para a classe \"Não relevante\", identificando corretamente todos os registros dessa classe. Isto pde ser devido aos dados de TF-IDF e sua associação com o tópico do documento, já que o tópico 3 não continha nenhum caso de emprea reslacionada ao objetivo, assim apontava a aqueles tópicos com menor probabilidade de conter uma empresa relevante.\n",
    "\n",
    "Com relação à classe \"Relevante\", com a precisão foi de 0.67 (67%) e o recall alcançando 1.00. Isso indica que, embora o modelo ainda faça algumas previsões incorretas para essa classe, ele foi capaz de identificar corretamente todos os registros \"Relevantes\" no conjunto de teste. O caso da precisão menor, ao contrario do \"não relevante\", possivelmente se deve a existerem registros de empresas relevantes em 3 dos 4 tópicos, e ao fato de que o número de registros relevantes é desproporcionalmente baixo se comparado ao número de registros \"não relevantes\".\n",
    "\n",
    "A classe com identificação mais problemática é a de \"Menos relevante\", com o modelo não conseguindo identificar corretamente nenhum registro dessa classe. Isso pode ser devido à falta de exemplos suficientes dessa classe no conjunto de treinamento ou a características menos distintivas que dificultam a diferenciação pelo modelo.\n",
    "\n",
    "Se comparado ao teste inicial, sem fine-tunig, as médias macro avg e weighted avg, assim como precisão e recall, mostram uma melhoria geral no desempenho do modelo em relação a todas as classes, refletindo os ganhos nas classes \"Não relevante\" e \"Relevante\". O primeiro teste, não incluído aqui, foi uma execução direta da Regressão Logística, sem fine-tuning.\n",
    "\n",
    "O quê poderia ser feito para melhorar o modelo: A \"rotulação\" de mais amostras, um melhor estudo qualitativo dos textos buscando outros termos associados, testes utilizando outras abordagens como similaridade entre os textos, para isto eu já tenho o TF-IDF, bastaria calcular a distância (possivelmente usando cosseno), desta forma poderia até criar escores alinhados a faixas de distâncias, a vantagem é que se vê válida especialmente pelas poucas amostras que se têm, mas exige maior tempo de análise. Na mesma linha poderia se aplicar clusterização, O k-means já faria esse agrupamento pelas distâncias.\n",
    "\n",
    "\n",
    "|Regressão Logística                                         |\n",
    "|------------------------------------------------------------|\n",
    "|Melhores parâmetros: {'C': 0.1, 'solver': 'saga'}           |\n",
    "\n",
    "|                 |  precision |  recall | f1-score | support|\n",
    "|:-:|:-:|:-:|:-|:-|\n",
    "| Menos relevante |     0.00   |   0.00  |    0.00  |      1 |\n",
    "|  Não relevante  |     1.00   |   1.00  |    1.00  |      5 |\n",
    "|      Relevante  |     0.67   |   1.00  |    0.80  |      2 |\n",
    "|------------------------------------------------------------|\n",
    "|       accuracy  |            |          |   0.88  |      8 |\n",
    "|      macro avg  |     0.56   |   0.67   |   0.60  |      8 |\n",
    "|   weighted avg  |     0.79   |   0.88   |   0.82  |      8 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
